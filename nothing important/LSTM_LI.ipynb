{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1895,
     "status": "ok",
     "timestamp": 1552964264426,
     "user": {
      "displayName": "Tseh Lee",
      "photoUrl": "",
      "userId": "00006482450783520423"
     },
     "user_tz": 420
    },
    "id": "XFtjc36YGj6N",
    "outputId": "72b49c52-2204-4499-8b8e-618c8e9df637"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/job:localhost/replica:0/task:0/device:GPU:0']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "import tensorflow as tf\n",
    "tf.set_random_seed(42)\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.layers import LSTM, Dropout\n",
    "from keras.layers import TimeDistributed\n",
    "from keras.layers.core import Dense, Activation, Dropout, RepeatVector\n",
    "from keras.optimizers import RMSprop\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import sys\n",
    "import heapq\n",
    "import seaborn as sns\n",
    "from pylab import rcParams\n",
    "from keras import backend as K\n",
    "print(K.tensorflow_backend._get_available_gpus())\n",
    "%matplotlib inline\n",
    "\n",
    "sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "\n",
    "rcParams['figure.figsize'] = 12, 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MmtVDWlg5BK4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 14986,
     "status": "ok",
     "timestamp": 1552964658858,
     "user": {
      "displayName": "Tseh Lee",
      "photoUrl": "",
      "userId": "00006482450783520423"
     },
     "user_tz": 420
    },
    "id": "W1wls_3T5Jmq",
    "outputId": "8002c302-c094-4c4b-a97c-8d763a2db68e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 232
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 419,
     "status": "error",
     "timestamp": 1552964276491,
     "user": {
      "displayName": "Tseh Lee",
      "photoUrl": "",
      "userId": "00006482450783520423"
     },
     "user_tz": 420
    },
    "id": "gyY_S0CYGSMk",
    "outputId": "bc7909ee-13b9-4dad-ec3d-6f44d0a0a292"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 505330926\n",
      "\"Here be our forecast\"\n",
      "\"Traveling to have a business meet take the fun out of the trip Especially if\n"
     ]
    }
   ],
   "source": [
    "path = 'train_set.txt'\n",
    "text = open(path).read()\n",
    "print('corpus length:', len(text))\n",
    "print(text[0:100])\n",
    "\n",
    "text = text[:300000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3190,
     "status": "ok",
     "timestamp": 1552786610646,
     "user": {
      "displayName": "Yuanzhe Li",
      "photoUrl": "",
      "userId": "02372743041431696661"
     },
     "user_tz": 420
    },
    "id": "mpUpPzY5GaV5",
    "outputId": "d44b2b40-62e2-4d1c-f0c5-df0cb7564c5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique chars: 55\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))\n",
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))\n",
    "\n",
    "print(f'unique chars: {len(chars)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z4Z8uDTO4cbW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3827,
     "status": "ok",
     "timestamp": 1552786611294,
     "user": {
      "displayName": "Yuanzhe Li",
      "photoUrl": "",
      "userId": "02372743041431696661"
     },
     "user_tz": 420
    },
    "id": "DfTKZ0cxGtru",
    "outputId": "04a765ab-ded7-4442-e2db-19a0f7c8f481"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num training examples: 99987\n"
     ]
    }
   ],
   "source": [
    "SEQUENCE_LENGTH = 40\n",
    "step = 3\n",
    "sentences = []\n",
    "next_chars = []\n",
    "for i in range(0, len(text) - SEQUENCE_LENGTH, step):\n",
    "    sentences.append(text[i: i + SEQUENCE_LENGTH])\n",
    "    next_chars.append(text[i + SEQUENCE_LENGTH])\n",
    "print(f'num training examples: {len(sentences)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4QSKtaR_Gumz"
   },
   "outputs": [],
   "source": [
    "X = np.zeros((len(sentences), SEQUENCE_LENGTH, len(chars)), dtype=np.bool)\n",
    "y = np.zeros((len(sentences), len(chars)), dtype=np.bool)\n",
    "for i, sentence in enumerate(sentences):\n",
    "    for t, char in enumerate(sentence):\n",
    "        X[i, t, char_indices[char]] = 1\n",
    "    y[i, char_indices[next_chars[i]]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "t8CvB9tHGz2n"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e even desire or necessary As far as the'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GkrRHqO5G1JK"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_chars[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "X-GhtBuzG7xV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False,  True, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w-9oKMXqG_OE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ucuClj8OHDav"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99987, 40, 55)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "03NE-yfKHG5P"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99987, 55)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "W15I9GiRHJeQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_1 (LSTM)                (None, 128)               94208     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 55)                7095      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 55)                0         \n",
      "=================================================================\n",
      "Total params: 101,303\n",
      "Trainable params: 101,303\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(SEQUENCE_LENGTH, len(chars))))\n",
    "model.add(Dense(len(chars)))\n",
    "model.add(Activation('softmax'))\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MpkVjMyKHMM5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From d:\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 94987 samples, validate on 5000 samples\n",
      "Epoch 1/20\n",
      "94987/94987 [==============================] - 42s 447us/step - loss: 2.1318 - acc: 0.4066 - val_loss: 1.9247 - val_acc: 0.4484\n",
      "Epoch 2/20\n",
      "94987/94987 [==============================] - 41s 435us/step - loss: 1.6796 - acc: 0.5211 - val_loss: 1.7375 - val_acc: 0.5158\n",
      "Epoch 3/20\n",
      "94987/94987 [==============================] - 41s 433us/step - loss: 1.5166 - acc: 0.5668 - val_loss: 1.6385 - val_acc: 0.5430\n",
      "Epoch 4/20\n",
      "94987/94987 [==============================] - 42s 437us/step - loss: 1.4216 - acc: 0.5910 - val_loss: 1.6049 - val_acc: 0.5522\n",
      "Epoch 5/20\n",
      "94987/94987 [==============================] - 41s 436us/step - loss: 1.3592 - acc: 0.6072 - val_loss: 1.5860 - val_acc: 0.5528\n",
      "Epoch 6/20\n",
      "94987/94987 [==============================] - 41s 435us/step - loss: 1.3174 - acc: 0.6180 - val_loss: 1.5941 - val_acc: 0.5558\n",
      "Epoch 7/20\n",
      "94987/94987 [==============================] - 41s 433us/step - loss: 1.2817 - acc: 0.6290 - val_loss: 1.5541 - val_acc: 0.5762\n",
      "Epoch 8/20\n",
      "94987/94987 [==============================] - 42s 442us/step - loss: 1.2562 - acc: 0.6353 - val_loss: 1.5827 - val_acc: 0.5682\n",
      "Epoch 9/20\n",
      "94987/94987 [==============================] - 42s 442us/step - loss: 1.2330 - acc: 0.6404 - val_loss: 1.5649 - val_acc: 0.5664\n",
      "Epoch 10/20\n",
      "94987/94987 [==============================] - 41s 436us/step - loss: 1.2146 - acc: 0.6450 - val_loss: 1.5778 - val_acc: 0.5648\n",
      "Epoch 11/20\n",
      "94987/94987 [==============================] - 41s 436us/step - loss: 1.1996 - acc: 0.6486 - val_loss: 1.5559 - val_acc: 0.5694\n",
      "Epoch 12/20\n",
      "94987/94987 [==============================] - 41s 435us/step - loss: 1.1827 - acc: 0.6531 - val_loss: 1.6144 - val_acc: 0.5642\n",
      "Epoch 13/20\n",
      "94987/94987 [==============================] - 42s 438us/step - loss: 1.1714 - acc: 0.6558 - val_loss: 1.5785 - val_acc: 0.5768\n",
      "Epoch 14/20\n",
      "94987/94987 [==============================] - 41s 435us/step - loss: 1.1586 - acc: 0.6585 - val_loss: 1.6030 - val_acc: 0.5600\n",
      "Epoch 15/20\n",
      "94987/94987 [==============================] - 42s 438us/step - loss: 1.1503 - acc: 0.6620 - val_loss: 1.6057 - val_acc: 0.5666\n",
      "Epoch 16/20\n",
      "94987/94987 [==============================] - 42s 442us/step - loss: 1.1377 - acc: 0.6651 - val_loss: 1.6021 - val_acc: 0.5706\n",
      "Epoch 17/20\n",
      "94987/94987 [==============================] - 42s 443us/step - loss: 1.1276 - acc: 0.6672 - val_loss: 1.6023 - val_acc: 0.5620\n",
      "Epoch 18/20\n",
      "94987/94987 [==============================] - 41s 435us/step - loss: 1.1188 - acc: 0.6701 - val_loss: 1.6007 - val_acc: 0.5762\n",
      "Epoch 19/20\n",
      "94987/94987 [==============================] - 227s 2ms/step - loss: 1.1108 - acc: 0.6724 - val_loss: 1.6055 - val_acc: 0.5748\n",
      "Epoch 20/20\n",
      "83072/94987 [=========================>....] - ETA: 34s - loss: 1.1007 - acc: 0.6775"
     ]
    }
   ],
   "source": [
    "optimizer = RMSprop(lr=0.01)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
    "history = model.fit(X, y, validation_split=0.05, batch_size=128, epochs=20, shuffle=True).history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "feaeE9tIHd6K"
   },
   "outputs": [],
   "source": [
    "model.save('keras_model.h5')\n",
    "pickle.dump(history, open(\"history.p\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Iq6x1jfrHezO"
   },
   "outputs": [],
   "source": [
    "model = load_model('keras_model.h5')\n",
    "history = pickle.load(open(\"history.p\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NQoeiIN6HjYP"
   },
   "outputs": [],
   "source": [
    "plt.plot(history['acc'])\n",
    "plt.plot(history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1C-qFoaLHpyc"
   },
   "outputs": [],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "idwaCzp7HqNT"
   },
   "outputs": [],
   "source": [
    "def prepare_input(text):\n",
    "    x = np.zeros((1, SEQUENCE_LENGTH, len(chars)))\n",
    "    for t, char in enumerate(text):\n",
    "        x[0, t, char_indices[char]] = 1.\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jOxlKkrPHtkX"
   },
   "outputs": [],
   "source": [
    "prepare_input(\"This is an example of input for our LSTM\".lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aeKrt_wrHwXb"
   },
   "outputs": [],
   "source": [
    "def sample(preds, top_n=3):\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds)\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    \n",
    "    return heapq.nlargest(top_n, range(len(preds)), preds.take)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jq_et1jVH0qy"
   },
   "outputs": [],
   "source": [
    "def predict_completion(text):\n",
    "    original_text = text\n",
    "    generated = text\n",
    "    completion = ''\n",
    "    while True:\n",
    "        x = prepare_input(text)\n",
    "        preds = model.predict(x, verbose=0)[0]\n",
    "        next_index = sample(preds, top_n=1)[0]\n",
    "        next_char = indices_char[next_index]\n",
    "        text = text[1:] + next_char\n",
    "        completion += next_char\n",
    "        \n",
    "        if len(original_text + completion) + 2 > len(original_text) and next_char == ' ':\n",
    "            return completion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zUQ16e6OH4Ry"
   },
   "outputs": [],
   "source": [
    "def predict_completions(text, n=3):\n",
    "    x = prepare_input(text)\n",
    "    preds = model.predict(x, verbose=0)[0]\n",
    "    next_indices = sample(preds, n)\n",
    "    return [indices_char[idx] + predict_completion(text[1:] + indices_char[idx]) for idx in next_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "MGSKBtnyH7Tc"
   },
   "outputs": [],
   "source": [
    "quotes = [\n",
    "    \"gas price change.I'm not upset that you lied to me, I'm upset that from now on I can't believe you\",\n",
    "    \"That which does not kill us makes us stronger.\",\n",
    "    \"I'm not upset that you lied to me, I'm upset that from now on I can't believe you.\",\n",
    "    \"And those who were seen dancing were thought to be insane by those who could not hear the music.\",\n",
    "    \"It is hard enough to remember my opinions, without also remembering my reasons for them!\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6QzurjYcLuyy"
   },
   "outputs": [],
   "source": [
    "for q in quotes:\n",
    "    seq = q[:40].lower()\n",
    "    print(seq)\n",
    "    print(predict_completions(seq, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GtOUyfaRLwzp"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "LSTM_LI.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
