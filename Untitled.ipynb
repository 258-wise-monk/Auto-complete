{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = []\n",
    "from os import listdir, chdir\n",
    "import re\n",
    "\n",
    "   \n",
    "# Here's the section where I try to filter useless stuff out.\n",
    "# Notice near the end all of the regex patterns where I've called \n",
    "# \"re.DOTALL\".  This is pretty key here.  What it means is that the\n",
    "# .+ I have referenced within the regex pattern should be able to \n",
    "# pick up alphanumeric characters, in addition to newline characters\n",
    "# (\\n).  Since I did not have this in the first version, the cautionary/\n",
    "# privacy messages people were pasting at the ends of their emails\n",
    "# were not getting filtered out and were being entered into the \n",
    "# LDA analysis, putting noise in the topics that were modelled.\n",
    "\n",
    "email_pat = re.compile(\".+@.+\")\n",
    "to_pat = re.compile(\"To:.+\\n\")\n",
    "cc_pat = re.compile(\"cc:.+\\n\")\n",
    "subject_pat = re.compile(\"Subject:.+\\n\")\n",
    "from_pat = re.compile(\"From:.+\\n\")\n",
    "sent_pat = re.compile(\"Sent:.+\\n\")\n",
    "received_pat = re.compile(\"Received:.+\\n\")\n",
    "ctype_pat = re.compile(\"Content-Type:.+\\n\")\n",
    "reply_pat = re.compile(\"Reply- Organization:.+\\n\")\n",
    "date_pat = re.compile(\"Date:.+\\n\")\n",
    "xmail_pat = re.compile(\"X-Mailer:.+\\n\")\n",
    "mimver_pat = re.compile(\"MIME-Version:.+\\n\")\n",
    "dash_pat = re.compile(\"--+.+--+\", re.DOTALL)\n",
    "star_pat = re.compile('\\*\\*+.+\\*\\*+', re.DOTALL)\n",
    "uscore_pat = re.compile(\" __+.+__+\", re.DOTALL)\n",
    "equals_pat = re.compile(\"==+.+==+\", re.DOTALL)\n",
    "\n",
    "# (the below is the same note as before)\n",
    "# The enron emails are in 151 directories representing each each senior management\n",
    "# employee whose email account was entered into the dataset.\n",
    "# The task here is to go into each folder, and enter each \n",
    "# email text file into one long nested list.\n",
    "# I've used readlines() to read in the emails because read() \n",
    "# didn't seem to work with these email files.\n",
    "\n",
    "chdir(\"/home/inkhorn/enron\")\n",
    "names = [d for d in listdir(\".\") if \".\" not in d]\n",
    "for name in names:\n",
    "    chdir(\"/home/inkhorn/enron/%s\" % name)\n",
    "    subfolders = listdir('.')\n",
    "    sent_dirs = [n for n, sf in enumerate(subfolders) if \"sent\" in sf]\n",
    "    sent_dirs_words = [subfolders[i] for i in sent_dirs]\n",
    "    for d in sent_dirs_words:\n",
    "        chdir('/home/inkhorn/enron/%s/%s' % (name,d))\n",
    "        file_list = listdir('.')\n",
    "        docs.append([\" \".join(open(f, 'r').readlines()) for f in file_list if \".\" in f])\n",
    "\n",
    "# (the below is the same note as before)\n",
    "# Here i go into each email from each employee, try to filter out all the useless stuff,\n",
    "# then paste the email into one long flat list.  This is probably inefficient, but oh well - python\n",
    "# is pretty fast anyway!\n",
    "\n",
    "docs_final = []\n",
    "for subfolder in docs:\n",
    "    for email in subfolder:\n",
    "        if \".nsf\" in email:\n",
    "            etype = \".nsf\"\n",
    "        elif \".pst\" in email:\n",
    "            etype = \".pst\"\n",
    "        email_new = email[email.find(etype)+4:]\n",
    "        email_new = to_pat.sub('', email_new)\n",
    "        email_new = cc_pat.sub('', email_new)\n",
    "        email_new = subject_pat.sub('', email_new)\n",
    "        email_new = from_pat.sub('', email_new)\n",
    "        email_new = sent_pat.sub('', email_new)\n",
    "        email_new = received_pat.sub('', email_new)\n",
    "        email_new = email_pat.sub('', email_new)\n",
    "        email_new = ctype_pat.sub('', email_new)\n",
    "        email_new = reply_pat.sub('', email_new)\n",
    "        email_new = date_pat.sub('', email_new)\n",
    "        email_new = xmail_pat.sub('', email_new)\n",
    "        email_new = mimver_pat.sub('', email_new)\n",
    "        email_new = dash_pat.sub('', email_new)\n",
    "        email_new = star_pat.sub('', email_new)\n",
    "        email_new = uscore_pat.sub('', email_new)\n",
    "        email_new = equals_pat.sub('', email_new)\n",
    "        docs_final.append(email_new)\n",
    "\n",
    "# (the below is the same note as before)\n",
    "# Here I proceed to dump each and every email into about 126 thousand separate \n",
    "# txt files in a newly created 'data' directory.  This gets it ready for entry into a Corpus using the tm (textmining)\n",
    "# package from R.\n",
    "\n",
    "for n, doc in enumerate(docs_final):\n",
    "    outfile = open(\"/home/inkhorn/enron/data/%s.txt\" % n,'w')\n",
    "    outfile.write(doc)\n",
    "    outfile.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
